<!DOCTYPE HTML>
<html lang="en">
<head>
	<title>VoiceBase Speech Engine: Titan</title>
	<meta name="googlebot" content="noindex">
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
	 <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
				

<script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', '253983637');
</script>
	<style>
		body {
			background-image: url("Asset21x.png");
}
@media only screen and (min-width: 415px) {
	body {
		background-image: url("Asset21x.png");
	}
} 
	#bigFont {
		font-family: "Montserrat:wght600&display=swap", sans-serif;
		font-size: 26px;
		color:#233E60;

	}
	#matchColorNew {
		background: white;
	}
	#matchColor {
		background: linear-gradient(to right, #081433 0%, #233E60 100%);
	}
 .center {
	/*text-align: center;*/
	list-style-position: inside;
	color:#000000;
}
ol.center li
{
	color: #000000;
 text-align: left;

 font-size: 16px;
}
.inlineList {
	 list-style: none; display: inline; }
}
.inlineList.after { content: " \00b7"; }
.inlineList.last-child.after { content: none; }

	h3 { font-family: Montserrat:wght600&display=swap; color:#233E60; }
	h4 { font-family: Montserrat:wght600&display=swap; color:#233E60; }
	p {color:#000000;font-size: 16px;}
	ul {color:#000000;font-size: 16px;}
	a {color:#0000CD;}
	

	</style>
</head>
<body>
<nav class="navbar navbar-inverse" id = "matchColorNew">
		<div class="container">
			<div class="navbar-header">
				<button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>	
					<a class="nav navbar-brand" ></a>
						<img class="img-responsive" src="logo2.png" style="height:30px; margin-top: 11px">
					</div>
			 <div class="collapse navbar-collapse" id="myNavbar">
			 <ul class="nav navbar-nav" id="bigFont">
			<!--  <li><img class="img-responsive" src="logo.png" style="height:30px; margin-top: 11px"></li> -->
			 <li><a id = "bigFont"  href="index.html">Help Center</a></li>
			 </ul>
			<ul class="nav navbar-nav navbar-right">
						<!-- <li class="active"><a href="index.html">Home</a></li> -->
						<li><a style = "color:#233E60; font-size: 16px;"href="http://info.voicebase.com/contact-sales">Talk to Sales</a></li>
						<li><a style = "color:#233E60; font-size: 16px;"href="https://www.voicebase.com/talk-to-support/">Talk to Support</a></li>
						 <li><a style = "color:#233E60; font-size: 16px;"href="https://apis.voicebase.com/developer-portal/#/">Developer Portal</a></li>
						 <li><a style = "color:#233E60; font-size: 16px;"href="http://status.voicebase.com/">System Status</a></li>
						 <li><a style = "color:#233E60; font-size: 16px;"href="https://www.voicebase.com">voicebase.com</a></li>
						

						</ul>
						</div>
				</div>
		</nav> 
		 <div class="container">
				<div class="row">
			<div class="col-md-12">
			<h3 style="text-align: center">Introducing VoiceBase's newest speech engine: Titan</h3>
				<hr>
			</div> 
			</div>
			<div class = "row">
				<div class = "col-md-12">
					<p class = "center">
					
					
						
<strong>Here at VoiceBase, we are excited to roll out our newest proprietary speech engine, “Titan”, supporting US English and Spanish.</strong> We think it’s worthy of the name due to its high accuracy and low cost. It’s been years in the making and shows off our team’s expertise and experience. But what sets it apart? To understand, we first need to peel back a few of the layers of how it’s made.<br><br>

So what’s under the hood of our speech engine? Also known as ASR, or an Automatic Speech Recognition system, Titan is the result of an acoustic model and a language model working together to give their best guess as to how to transcribe each word. Acoustic models model the way that a speaker pronounces the words in a word sequence. A language model learns the probability of word occurrence based on examples of text. <br><br>

But how does that work? The acoustic model is fed short segments of audio of around 25 ms each, and its first task is to match each segment with its corresponding pronunciation or ‘phoneme’. Ultimately its goal is to predict which phoneme is spoken in each segment of audio. This is accomplished by Deep Learning processes and techniques where it “learns” through its training data, which are sets of audio and corresponding transcriptions.<br><br>

Whereas the acoustic model’s goal tends more toward the black and white in that either a phoneme matches or does not, the language model explores human culture as it appears in language: speech patterns, common utterances, and the way words are most likely to be linked together. After being trained on a large data set, the language model becomes able to predict what word will most likely follow another. For example, “flowers” will most likely follow “blooming”, or “skies” might follow “blue”. Once the language model is trained, it can then choose the correct context for a word, successfully distinguishing between homonyms. <br><br>

While the combination of acoustic and language models is common to all modern speech engines, <strong>Titan’s inner structure is unique in a few ways:</strong><br><br>

First, VoiceBase used state of the art technology to train the models, developed at the <a href="https://www.sheffield.ac.uk/dcs/news/university-sheffield-partners-voicebase-launch-centre-speech-language-technology">VoiceBase Centre for Speech and Language Technology</a> at the University of Sheffield, UK. Our collaboration with this outstanding department of researchers has been in place since 2018, allowing our team at VoiceBase to contribute to and learn from the originality, rigor, and significance of their work.<br><br>

Second, the data used to train Titan drew exclusively from call center audio - 7700 hours of it, in fact. This means that the characteristics specific to this type of call, such as background noise, vocabulary, common phrases, and the like are well known to the acoustic and language models employed. While resilient to the background noise, the models also are extremely familiar with the way humans typically express their wants, needs, and frustrations when speaking to a customer service agent. <strong>Training the models on this specific dataset is an important reason for Titan’s accuracy in transcription for call center audio.</strong><br><br>

					</p>

					<hr>


							
						</div>

			<script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/1701619.js"></script>
		 </body>
 </html>     